import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, accuracy_score
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.utils import to_categorical

column_names = [
    'letter', 'x-box', 'y-box', 'width', 'high', 'onpix', 'x-bar', 'y-bar',
    'x2bar', 'y2bar', 'xybar', 'x2ybr', 'xy2br', 'x-ege', 'xegvy', 'y-ege', 'yegvx'
]
df = pd.read_csv("/content/drive/MyDrive/DL_Datasets/Assignment_2/multi_class_classification/letter-recognition.data", header=None, names=column_names)
df.head()

# Encode labels (A-Z) into integers 0-25
le = LabelEncoder()
df['letter'] = le.fit_transform(df['letter'])

# Split features and target
X = df.drop('letter', axis=1)
y = df['letter']

# Standardize features
scaler = StandardScaler()
X = scaler.fit_transform(X)
     

# One-hot encode target labels
y = to_categorical(y)
     

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
     

model = models.Sequential([
    layers.Dense(128, activation='relu', input_shape=(16,)),
    layers.Dropout(0.3),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(26, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
     

# Train the model
history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1)
     

loss, acc = model.evaluate(X_test, y_test)
print(loss)
print(acc)
     

# Predict and decode a few samples
predictions = model.predict(X_test[1:5])
predicted_classes = le.inverse_transform(np.argmax(predictions, axis=1))
true_classes = le.inverse_transform(np.argmax(y_test[1:5], axis=1))
print("Predicted:", predicted_classes)
print("True:", true_classes)
